# Root directory for the project
ROOT: .

# Project name
PROJ: tutorial

# Metadata file
METADATA: Pereira/Pereira_data.csv
fwd_reads_path: forward_reads
rev_reads_path: reverse_reads

################################################
### TRIMMOMATIC ADAPTER AND QUALITY TRIMMING ###
# minimum read length after trimming
min_readlen: 50
# the minimum quality for the start of a read. If it's below this quality, trim that base pair
readstart_qual_min: 20
# the minimum quality for the end of a read. If it's below this quality, trim that base pair
readend_qual_min: 20

######################
### SEQTK TRIMMING ###
# This is a second pass hard trimming, after trimmomatic has done quality-based and adapter trimming
# Read trimming this many base pairs from the start of the read
trim_fwd: 0
trim_rev: 0

# Read truncating this many base pairs from the end of the read
trunc_fwd: 0
trunc_rev: 0

############################
### Hostile host read removal ###
# Database for host read removal
# Current supported options include:
# - human-t2t-hla
# - human-t2t-hla-argos985
# - filepath to an already downloaded and bowtie2-indexed database 
#   (with no .bt1, .bt2 etc file extensions in this argument)
hostile_db: human-t2t-hla-argos985
# Where to download a database for hostile (if applicable)
loc_for_hostile_db_download: data


#################################
### HUMAnN BioBakery pipeline ###

# Path to MetaPhlan bowtie database (step 1 of HUMAnN)
metaphlan_bowtie_db: data/metaphlan_db/

# Paths to Chocophlan and UniRef databases for HUMAnN
# If these aren't already downloaded, HoMi will download them
chocophlan_db: data/humann_dbs/chocophlan
uniref_db: data/humann_dbs/uniref
utility_mapping_db: data/humann_dbs/utility_mapping 


########################
### Kraken + Bracken ###
# database location
kraken_db: synthetic/data/kraken2_db
# host taxon ID to not be plotted in microbial taxa barplot
host_tax_id: 9606


#################################
### Host read mapping ###
# provide the path for the host reference genome
# if these files do not exist yet, HoMi will by default download the GRCh38 human reference genome
host_ref_fna: data/GRCh38/GRCh38_full_analysis_set.fna 
host_ref_gtf: data/GRCh38/GRCh38_full_analysis_set.refseq.gtf

# Specifying the host mapping method here. options include BBMap and HISAT2
host_map_method: HISAT2

################################
### Resources ###
# Rules will use the default resources outlined for them in the snakefile, 
# unless you provide other resource specifications here.
# these should be formatted as <rule_name>_<resource>
# examples:
# rule_name_partition: new_partition
# rule_name_mem_mb: 10000 # (10 GB)
# rule_name_runtime: 600 # (10 hours)
# rule_name_threads: 8 

################################
### Partition ###
# This is an optional resource parameter to map partitions named: 
# "short" --> default_short_partition_name
# "long" --> default_long_partition_name
# If nothing is here, nothing will be done
# For example, Alpine users at CU Boulder/Anschutz CSU using the amilan partition for most rules can pass
# default_short_partition_name: amilan

default_short_partition_name: short
default_long_partition_name: long

################################
### Slurm Extras ###
# For cluster use, users may want to pass slurm extra parameters
# This can be done using default_slurm_extra, which will serve as a default for all steps
# or by using <rule_name>_slurm_extra, which provides rule-specific slurm extra parameters.
# Rule-specific parameters are prioritized over default params.
# These parameters should be a space-separated list, formatted as
# <slurm_long_name>=<parameter> <slurm_long_name_2>=<parameter_2>
# examples:
# default_slurm_extra: email=sample_email@colorado.edu
# map_host_slurm_extra: qos=long email=sample_email@colorado.edu
# All rules would receive the email param, 
# and the bbmap host rule would also receive the qos param
